{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0cddf3f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c75edb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d54a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23680 23680\n",
      "Found 23680 images belonging to 1 classes.\n",
      "Found 23680 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "list_image = sorted(glob(os.getenv(\"HOME\")+'/lfw/data/train/input/img/*.png'))\n",
    "list_label = sorted(glob(os.getenv(\"HOME\")+'/lfw/data/train/label/mask/*.png'))\n",
    "print (len(list_image), len(list_label))\n",
    "\n",
    "IMAGE_SHAPE = (80, 120)\n",
    "data_root = os.getenv(\"HOME\")+'/lfw/data/train/input'\n",
    "label_root = os.getenv(\"HOME\")+'/lfw/data/train/label'\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "label_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "image_data = image_generator.flow_from_directory(str(data_root), class_mode=None, target_size=IMAGE_SHAPE, batch_size=10)\n",
    "label_data = label_generator.flow_from_directory(str(label_root), class_mode=None, target_size=IMAGE_SHAPE, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60176b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_generation(train_generator, label_generator):\n",
    "    h, w = train_generator.target_size\n",
    "    for images, labels in zip(train_generator, label_generator):\n",
    "        images /= 255.\n",
    "        images = images[..., ::-1] # rgb to bgr\n",
    "\n",
    "        list_point_labels = []\n",
    "        for img, label in zip(images, labels):\n",
    "\n",
    "            eye_ls = np.where(label==1) # leftside\n",
    "            eye_rs = np.where(label==2) # rightside\n",
    "            eye_center = np.where(label==3)\n",
    "\n",
    "            lx, ly = [eye_ls[1].mean(), eye_ls[0].mean()]\n",
    "            rx, ry = [eye_rs[1].mean(), eye_rs[0].mean()]\n",
    "            cx, cy = [eye_center[1].mean(), eye_center[0].mean()]\n",
    "\n",
    "            if len(eye_ls[0])==0 or len(eye_ls[1])==0:\n",
    "                lx, ly = [0, 0]\n",
    "            if len(eye_rs[0])==0 or len(eye_rs[1])==0:\n",
    "                rx, ry = [w, h]\n",
    "            if len(eye_center[0])==0 or len(eye_center[1])==0:\n",
    "                cx, cy = [0, 0]\n",
    "\n",
    "            np_point_label = np.array([lx/w,ly/h,rx/w,ry/h,cx/w,cy/h], dtype=np.float32)\n",
    "\n",
    "            list_point_labels.append(np_point_label)\n",
    "        np_point_labels = np.array(list_point_labels)\n",
    "        yield (images, np_point_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85afd227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 120, 3) [0.         0.         1.         1.         0.54878384 0.35477474]\n",
      "(80, 120, 3) [0.        0.        1.        1.        0.7125    0.3545045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj51/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "/home/aiffel-dj51/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/aiffel-dj51/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "user_train_generator = user_generation(image_data, label_data)\n",
    "for i in range(2):\n",
    "    dd = next(user_train_generator)\n",
    "    print (dd[0][0].shape, dd[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9287d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2048)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f0265629950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f0265629950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f0265629950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 23,577,094\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' tf hub feature_extractor '''\n",
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                            input_shape=(80,120,3))\n",
    "\n",
    "image_batch = next(image_data)\n",
    "feature_batch = feature_extractor_layer(image_batch)\n",
    "print(feature_batch.shape)\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "feature_extractor_layer.trainable = False\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    #layers.Dense(1024, activation='relu'),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966cc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss='mse',\n",
    "  metrics=['mae']\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e030654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_step_decay(epoch):\n",
    "      init_lr = 0.0005 #self.flag.initial_learning_rate\n",
    "      lr_decay = 0.5 #self.flag.learning_rate_decay_factor\n",
    "      epoch_per_decay = 2 #self.flag.epoch_per_decay\n",
    "      lrate = init_lr * math.pow(lr_decay, math.floor((1+epoch)/epoch_per_decay))\n",
    "      return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd738192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23680 10 2368\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj51/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "/home/aiffel-dj51/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368/2368 [==============================] - 25s 9ms/step - loss: 0.0250 - mae: 0.0776\n",
      "Epoch 2/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0140 - mae: 0.0546\n",
      "Epoch 3/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0136 - mae: 0.0535\n",
      "Epoch 4/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0131 - mae: 0.0524\n",
      "Epoch 5/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0129 - mae: 0.0519\n",
      "Epoch 6/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0128 - mae: 0.0515\n",
      "Epoch 7/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0128 - mae: 0.0515\n",
      "Epoch 8/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0126 - mae: 0.0513\n",
      "Epoch 9/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0126 - mae: 0.0513\n",
      "Epoch 10/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0125 - mae: 0.0511\n",
      "Epoch 11/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0123 - mae: 0.0507\n",
      "Epoch 12/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0125 - mae: 0.0511\n",
      "Epoch 13/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0125 - mae: 0.0512\n",
      "Epoch 14/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0126 - mae: 0.0513\n",
      "Epoch 15/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0123 - mae: 0.0507\n",
      "Epoch 16/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0123 - mae: 0.0506\n",
      "Epoch 17/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0125 - mae: 0.0511\n",
      "Epoch 18/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0123 - mae: 0.0507\n",
      "Epoch 19/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0509\n",
      "Epoch 20/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0126 - mae: 0.0512\n",
      "Epoch 21/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0123 - mae: 0.0506\n",
      "Epoch 22/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0126 - mae: 0.0511\n",
      "Epoch 23/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0123 - mae: 0.0506\n",
      "Epoch 24/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0125 - mae: 0.0510\n",
      "Epoch 25/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0125 - mae: 0.0511\n",
      "Epoch 26/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0123 - mae: 0.0505\n",
      "Epoch 27/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0125 - mae: 0.0510\n",
      "Epoch 28/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0124 - mae: 0.0507\n",
      "Epoch 29/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0124 - mae: 0.0508\n",
      "Epoch 30/50\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 0.0124 - mae: 0.0508\n",
      "Epoch 31/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0507\n",
      "Epoch 32/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0509\n",
      "Epoch 33/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0508\n",
      "Epoch 34/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0123 - mae: 0.0507\n",
      "Epoch 35/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0509\n",
      "Epoch 36/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0508\n",
      "Epoch 37/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0509\n",
      "Epoch 38/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0125 - mae: 0.0509\n",
      "Epoch 39/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0508\n",
      "Epoch 40/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0508\n",
      "Epoch 41/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0123 - mae: 0.0507\n",
      "Epoch 42/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0509\n",
      "Epoch 43/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0508\n",
      "Epoch 44/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0125 - mae: 0.0510\n",
      "Epoch 45/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0509\n",
      "Epoch 46/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0123 - mae: 0.0506\n",
      "Epoch 47/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0125 - mae: 0.0510\n",
      "Epoch 48/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0125 - mae: 0.0510\n",
      "Epoch 49/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0510\n",
      "Epoch 50/50\n",
      "2368/2368 [==============================] - 23s 10ms/step - loss: 0.0124 - mae: 0.0507\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = image_data.samples//image_data.batch_size\n",
    "print (image_data.samples, image_data.batch_size, steps_per_epoch)\n",
    "# 20160 32 630 -> 데이터를 batch_size 의 배수로 준비해 주세요.\n",
    "\n",
    "learning_rate = LearningRateScheduler(lr_step_decay)\n",
    "\n",
    "history = model.fit(user_train_generator, epochs=50,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    callbacks = [learning_rate]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ff3da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2640 images belonging to 1 classes.\n",
      "Found 2640 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (80, 120)\n",
    "\n",
    "val_data_root = os.getenv(\"HOME\")+'/lfw/data/val/input'\n",
    "val_label_root = os.getenv(\"HOME\")+'/lfw/data/val/label'\n",
    "\n",
    "image_generator_val = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "label_generator_val = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "image_data_val = image_generator.flow_from_directory(str(val_data_root), class_mode=None, target_size=IMAGE_SHAPE, shuffle=False)\n",
    "label_data_val = label_generator.flow_from_directory(str(val_label_root), class_mode=None, target_size=IMAGE_SHAPE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab39a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj51/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n",
      "/home/aiffel-dj51/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "/home/aiffel-dj51/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012538482435047626 0.050743456929922104\n"
     ]
    }
   ],
   "source": [
    "user_val_generator = user_generation(image_data_val, label_data_val)\n",
    "mse, mae = model.evaluate_generator(user_val_generator, image_data_val.n // 32)\n",
    "print(mse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "560cb33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# img test\n",
    "img = cv2.imread(os.getenv(\"HOME\")+'/lfw/data/val/input/img/eye_000010_l.png')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2ac9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3.5596904e-03 8.5805054e-04]\n",
      "  [1.1999894e+02 7.9999573e+01]\n",
      "  [5.3541374e+01 2.7846123e+01]]]\n"
     ]
    }
   ],
   "source": [
    "np_inputs = np.expand_dims(cv2.resize(img, (120, 80)), axis=0)\n",
    "preds = model.predict(np_inputs/255., 1)\n",
    "\n",
    "repred = preds.reshape((1, 3, 2))\n",
    "repred[:,:,0] *= 120\n",
    "repred[:,:,1] *= 80\n",
    "print (repred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acdd87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[120.  80.]\n",
      "[54. 28.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show = img.copy()\n",
    "for pt in repred[0]:\n",
    "    print (pt.round())\n",
    "    show = cv2.circle(show, tuple((pt*0.15).astype(int)), 3, (0,255,255), -1)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(show, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f90d2",
   "metadata": {},
   "source": [
    "### 느낀점 (회고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5813efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean-shift를 활용하여 눈동자 검출 라벨링 추가작업을 원활히 진행하였다. 눈동자 키포인트 검출 딥러닝 모델이 구현되어 안정적으로 학습이 진행되었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
