{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organic-scoop",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satisfied-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-pittsburgh",
   "metadata": {},
   "source": [
    "### Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amber-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filepath =  os.getenv('HOME') + '/aiffel/songys_chatbot/ChatbotData .csv'\n",
    "chatbot_data = pd.read_csv(dataset_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impressive-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-rolling",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "finnish-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "likely-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅣ가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "criminal-printing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12시 땡 !'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '12시 땡!'\n",
    "preprocess_sentence(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "infinite-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations(questions, answers):\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    for question, answer in zip(questions, answers):\n",
    "        inputs.append(preprocess_sentence(question))\n",
    "        outputs.append(preprocess_sentence(answer))\n",
    "        \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solved-watershed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = load_conversations(chatbot_data['Q'], chatbot_data['A'])\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modern-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-relation",
   "metadata": {},
   "source": [
    "### Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "complimentary-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fancy-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "radio-pleasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8170]\n",
      "END_TOKEN의 번호 : [8171]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :', [tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :', [tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "technical-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8172\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "royal-concord",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5761, 610, 2490, 4163]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2356, 7510, 7, 6273, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "psychological-confusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이.\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "authorized-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "disciplinary-general",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8172\n",
      "필터링 후의 샘플 개수: 11823\n",
      "필터링 후의 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :', (VOCAB_SIZE))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-commons",
   "metadata": {},
   "source": [
    "### Step 4. 모델 구성하기 - Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "honest-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositionalEncoding Layer\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) /\n",
    "                            tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "superior-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_dot_product_attention\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "french-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        # 스케일드 닷-프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(\n",
    "            query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "associate-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "universal-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - \\\n",
    "        tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "guided-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "     # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "intellectual-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "assigned-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "     # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "    \n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "    \n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "industrial-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    \n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-midwest",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-practice",
   "metadata": {},
   "source": [
    "- teacher forcing사용\n",
    "    - answer[:,:-1]를 디코더의 입력값, answer[:,1:]를 디코더의 레이블로 사용한다\n",
    "- tf.data.Dataset API활용, 파이프라인 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "random-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "taken-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크하기위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # encoder\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "    \n",
    "    # decoder\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(\n",
    "        units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "multiple-mambo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, None, 512)    13651968    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, None, 512)    19961856    dec_inputs[0][0]                 \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8172)   4192236     decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 37,806,060\n",
      "Trainable params: 37,806,060\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6  # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512  # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8  # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 512  # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1  # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "alpha-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "alert-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "handed-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hungarian-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 35s 189ms/step - loss: 1.3430 - accuracy: 0.0236\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 35s 191ms/step - loss: 1.0749 - accuracy: 0.0492\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 36s 197ms/step - loss: 0.9801 - accuracy: 0.0508\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 39s 208ms/step - loss: 0.9365 - accuracy: 0.0530\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.9035 - accuracy: 0.0550\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.8667 - accuracy: 0.0571\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.8267 - accuracy: 0.0595\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.7787 - accuracy: 0.0625\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 36s 196ms/step - loss: 0.7219 - accuracy: 0.0668\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.6617 - accuracy: 0.0723\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.5997 - accuracy: 0.0792\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 36s 193ms/step - loss: 0.5391 - accuracy: 0.0862\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.4809 - accuracy: 0.0933\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.4287 - accuracy: 0.1006\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 36s 193ms/step - loss: 0.3837 - accuracy: 0.1064\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.3452 - accuracy: 0.1115\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 36s 193ms/step - loss: 0.3145 - accuracy: 0.1151\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 36s 193ms/step - loss: 0.2908 - accuracy: 0.1183\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 37s 199ms/step - loss: 0.2712 - accuracy: 0.1209\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.2567 - accuracy: 0.1229\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.2433 - accuracy: 0.1248\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.2343 - accuracy: 0.1259\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.2215 - accuracy: 0.1281\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.2045 - accuracy: 0.1304\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.1925 - accuracy: 0.1325\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.1795 - accuracy: 0.1347\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 36s 196ms/step - loss: 0.1687 - accuracy: 0.1362\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 37s 198ms/step - loss: 0.1586 - accuracy: 0.1380\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.1478 - accuracy: 0.1399\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 36s 196ms/step - loss: 0.1390 - accuracy: 0.1415\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 37s 198ms/step - loss: 0.1318 - accuracy: 0.1428\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.1250 - accuracy: 0.1444\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.1172 - accuracy: 0.1457\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 37s 198ms/step - loss: 0.1130 - accuracy: 0.1464\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 36s 196ms/step - loss: 0.1069 - accuracy: 0.1479\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 38s 203ms/step - loss: 0.1005 - accuracy: 0.1489\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 36s 196ms/step - loss: 0.0958 - accuracy: 0.1502\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 36s 196ms/step - loss: 0.0929 - accuracy: 0.1506\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.0873 - accuracy: 0.1518\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.0834 - accuracy: 0.1530\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.0795 - accuracy: 0.1537\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.0754 - accuracy: 0.1546\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.0715 - accuracy: 0.1558\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.0688 - accuracy: 0.1563\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.0664 - accuracy: 0.1568\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.0624 - accuracy: 0.1579\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 36s 195ms/step - loss: 0.0597 - accuracy: 0.1585\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.0571 - accuracy: 0.1592\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.0551 - accuracy: 0.1596\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 36s 194ms/step - loss: 0.0528 - accuracy: 0.1602\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "floral-shuttle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.title('accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['accuracy'], loc='best')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.legend(['loss'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-programmer",
   "metadata": {},
   "source": [
    "### Step 5. 모델 평가하기- Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "driving-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞 뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pharmaceutical-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "american-airport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 가장 졸리운 건 뭘까\n",
      "출력 : 여유를 갖고 찾아보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'여유를 갖고 찾아보세요 .'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"가장 졸리운 건 뭘까\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-diana",
   "metadata": {},
   "source": [
    "### 느낀점(회고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-institution",
   "metadata": {},
   "source": [
    "Transformer를 이용하여 한국어 대화용 챗봇을 만들었습니다.\n",
    "learning rate scheduling의 새로운 방법에 대해서 알게되어 더 공부해볼 필요가 있다고 생각합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
